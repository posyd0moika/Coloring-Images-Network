{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Lambda\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_cl = keras.applications.VGG19()\n",
    "vgg19_cl.trainable = False\n",
    "vgg19_cl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_imag\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_90 (Conv2D)          (None, 224, 224, 64)      640       \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 112, 112, 64)      36928     \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 56, 56, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 28, 28, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 28, 28, 1024)      4719616   \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 28, 28, 1024)      9438208   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,482,240\n",
      "Trainable params: 16,482,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_inp = keras.Sequential(name=\"conv_imag\")\n",
    "model_inp.add(InputLayer(input_shape=(224, 224, 1)))\n",
    "model_inp.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model_inp.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model_inp.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model_inp.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model_inp.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model_inp.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model_inp.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model_inp.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
    "model_inp.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
    "model_inp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = keras.Sequential()\n",
    "model_out.add(InputLayer(input_shape=(28, 28, 1025)))\n",
    "model_out.add(UpSampling2D((2, 2)))\n",
    "model_out.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model_out.add(UpSampling2D((2, 2)))\n",
    "model_out.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model_out.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model_out.add(UpSampling2D((2, 2)))\n",
    "model_out.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_conv = InputLayer((224, 224, 1))\n",
    "\n",
    "\n",
    "# def func(x1, x2):\n",
    "#     \"\"\"\n",
    "#\n",
    "#     :param x1:  shape = (28, 28, 1024)\n",
    "#     :param x2: shape = (1000, )\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     n1 = tf.Variable()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
